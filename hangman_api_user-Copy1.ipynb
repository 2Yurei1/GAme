{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trexquant Interview Project (The Hangman Game)\n",
    "\n",
    "* Copyright Trexquant Investment LP. All Rights Reserved. \n",
    "* Redistribution of this question without written consent from Trexquant is prohibited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction:\n",
    "For this coding test, your mission is to write an algorithm that plays the game of Hangman through our API server. \n",
    "\n",
    "When a user plays Hangman, the server first selects a secret word at random from a list. The server then returns a row of underscores (space separated)—one for each letter in the secret word—and asks the user to guess a letter. If the user guesses a letter that is in the word, the word is redisplayed with all instances of that letter shown in the correct positions, along with any letters correctly guessed on previous turns. If the letter does not appear in the word, the user is charged with an incorrect guess. The user keeps guessing letters until either (1) the user has correctly guessed all the letters in the word\n",
    "or (2) the user has made six incorrect guesses.\n",
    "\n",
    "You are required to write a \"guess\" function that takes current word (with underscores) as input and returns a guess letter. You will use the API codes below to play 1,000 Hangman games. You have the opportunity to practice before you want to start recording your game results.\n",
    "\n",
    "Your algorithm is permitted to use a training set of approximately 250,000 dictionary words. Your algorithm will be tested on an entirely disjoint set of 250,000 dictionary words. Please note that this means the words that you will ultimately be tested on do NOT appear in the dictionary that you are given. You are not permitted to use any dictionary other than the training dictionary we provided. This requirement will be strictly enforced by code review.\n",
    "\n",
    "You are provided with a basic, working algorithm. This algorithm will match the provided masked string (e.g. a _ _ l e) to all possible words in the dictionary, tabulate the frequency of letters appearing in these possible words, and then guess the letter with the highest frequency of appearence that has not already been guessed. If there are no remaining words that match then it will default back to the character frequency distribution of the entire dictionary.\n",
    "\n",
    "This benchmark strategy is successful approximately 18% of the time. Your task is to design an algorithm that significantly outperforms this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import random\n",
    "import string\n",
    "import secrets\n",
    "import time\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    from urllib.parse import parse_qs, urlencode, urlparse\n",
    "except ImportError:\n",
    "    from urlparse import parse_qs, urlparse\n",
    "    from urllib import urlencode\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giris\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_spelled_words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class HangmanAPI(object):\n",
    "    def __init__(self, access_token=None, session=None, timeout=None):\n",
    "        self.hangman_url = self.determine_hangman_url()\n",
    "        self.access_token = access_token\n",
    "        self.session = session or requests.Session()\n",
    "        self.timeout = timeout\n",
    "        self.guessed_letters = []\n",
    "        \n",
    "        full_dictionary_location = \"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)        \n",
    "        self.full_dictionary_common_letter_sorted = collections.Counter(\"\".join(self.full_dictionary)).most_common()\n",
    "        \n",
    "        self.current_dictionary = []\n",
    "        self.letter_set = sorted(set(\"\".join(self.full_dictionary)))\n",
    "        self.probabilities = [0] * len(self.letter_set)\n",
    "        \n",
    "        self.trigram_probs = self.calculate_trigram_probabilities('word')\n",
    "    \n",
    "        self.unigram, self.bigram, self.trigram, self.fourgram, self.fivegram = self.build_n_grams(self.full_dictionary)\n",
    "    \n",
    "        self.spelling_model = self.build_spelling_model()\n",
    "        self.tokenizer, self.model, self.encoder_model, self.decoder_model, self.max_encoder_seq_length = self.build_spelling_model()\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def determine_hangman_url():\n",
    "        links = ['https://trexsim.com', 'https://sg.trexsim.com']\n",
    "\n",
    "        data = {link: 0 for link in links}\n",
    "\n",
    "        for link in links:\n",
    "\n",
    "            requests.get(link)\n",
    "\n",
    "            for i in range(10):\n",
    "                s = time.time()\n",
    "                requests.get(link)\n",
    "                data[link] = time.time() - s\n",
    "\n",
    "        link = sorted(data.items(), key=lambda x: x[1])[0][0]\n",
    "        link += '/trexsim/hangman'\n",
    "        return link\n",
    "    # ... (previous code remains unchanged)\n",
    "    \n",
    "    \n",
    "    def build_spelling_model(self):\n",
    "        # Load your dictionary\n",
    "        correctly_spelled_words = []\n",
    "        with open('words_250000_train.txt', 'r') as file:\n",
    "            correctly_spelled_words = [line.strip() for line in file]\n",
    "\n",
    "        # Generate synthetic data\n",
    "        synthetic_data = [(self.introduce_misspellings(word), word) for word in correctly_spelled_words]\n",
    "\n",
    "        # Prepare tokenizer\n",
    "        input_texts = [d[0] for d in synthetic_data]\n",
    "        target_texts = [d[1] for d in synthetic_data]\n",
    "        tokenizer = Tokenizer(char_level=True)\n",
    "        tokenizer.fit_on_texts(input_texts + target_texts)\n",
    "\n",
    "        num_encoder_tokens = len(tokenizer.word_index)\n",
    "        num_decoder_tokens = len(tokenizer.word_index)\n",
    "        max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "        max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "        latent_dim = 256  # Adjust as needed\n",
    "\n",
    "        # Define encoder\n",
    "        encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "        encoder = LSTM(latent_dim, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "        encoder_states = [state_h, state_c]\n",
    "        \n",
    "        \n",
    "         # Define encoder model\n",
    "        encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "        # Define decoder\n",
    "        decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "        decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "        decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        # Define the full model\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "       \n",
    "\n",
    "        # Define decoder model\n",
    "        decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "        decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        decoder_model = Model(\n",
    "            [decoder_inputs] + decoder_states_inputs,\n",
    "            [decoder_outputs] + decoder_states)\n",
    "\n",
    "        return tokenizer, model, encoder_model, decoder_model, max_encoder_seq_length\n",
    "\n",
    "    # ... (rest of your methods)\n",
    "\n",
    "\n",
    "    def introduce_misspellings(self, word):\n",
    "        misspelled_word = list(word)\n",
    "    \n",
    "    # Randomly choose an operation: substitute, delete, or insert a character\n",
    "        operations = ['substitute', 'delete', 'insert']\n",
    "        operation = random.choice(operations)\n",
    "     \n",
    "        if operation == 'substitute':\n",
    "            index = random.randint(0, len(misspelled_word) - 1)\n",
    "            misspelled_word[index] = chr(random.randint(97, 122))  # Random lowercase letter\n",
    "        elif operation == 'delete' and len(misspelled_word) > 1:\n",
    "            index = random.randint(0, len(misspelled_word) - 1)\n",
    "            del misspelled_word[index]\n",
    "        elif operation == 'insert':\n",
    "            index = random.randint(0, len(misspelled_word))\n",
    "            misspelled_word.insert(index, chr(random.randint(97, 122)))\n",
    "    \n",
    "        return ''.join(misspelled_word)\n",
    " \n",
    "       # Generate synthetic data\n",
    "    synthetic_data = [(introduce_misspellings(word), word) for word in correctly_spelled_words]\n",
    "        # ... (your existing introduce_misspellings function) ...\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def decode_sequence(self, input_seq):\n",
    "        # Encode the input as state vectors.\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1, 1, len(self.tokenizer.word_index)))\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "        decoded_sentence = ''\n",
    "        stop_condition = False\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = tokenizer.index_word[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "            if len(decoded_sentence) > max_decoder_seq_length:\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1, 1, num_tokens))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "            states_value = [h, c]\n",
    "\n",
    "        return decoded_sentence\n",
    "    def guess_using_spelling_model(self, clean_word):\n",
    "    # Prepare the input sequence\n",
    "        input_seq = self.tokenizer.texts_to_sequences([clean_word.replace('_', 'x')])  # Replace underscore with 'x' or any other character\n",
    "        input_seq = pad_sequences(input_seq, maxlen=self.max_encoder_seq_length, padding='post')\n",
    "    \n",
    "    # One-hot encode the input sequence\n",
    "        input_seq_one_hot = np.zeros((1, input_seq.shape[1], len(self.tokenizer.word_index) + 1))\n",
    "        for i, seq in enumerate(input_seq):\n",
    "            input_seq_one_hot[i, np.arange(len(seq)), seq] = 1.\n",
    "\n",
    "    # Get the corrected word\n",
    "        corrected_word = self.decode_sequence(input_seq_one_hot)\n",
    "\n",
    "    # Find the first letter in the corrected word that isn't in the current word and hasn't been guessed\n",
    "        for letter in corrected_word:\n",
    "            if letter not in clean_word and letter not in self.guessed_letters:\n",
    "                return letter\n",
    "\n",
    "    # If no suitable letter found, fall back to frequency-based guess\n",
    "        return self.guess_by_overall_frequency()\n",
    "  \n",
    "    def decode_sequence(self, input_seq):\n",
    "      # Encode the input as state vectors.\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1, 1, len(self.tokenizer.word_index) + 1))\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "        decoded_sentence = ''\n",
    "        stop_condition = False\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_char = self.tokenizer.index_word[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "            if len(decoded_sentence) > self.max_encoder_seq_length:\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1, 1, len(self.tokenizer.word_index) + 1))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "            states_value = [h, c]\n",
    "\n",
    "        return decoded_sentence\n",
    "\n",
    "#     # Prepare inference model\n",
    "#     encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#     decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "#     decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "#     decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "#     decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "#         decoder_embedding, initial_state=decoder_states_inputs)\n",
    "#     decoder_states = [state_h, state_c]\n",
    "#     decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#     decoder_model = Model(\n",
    "#         [decoder_inputs] + decoder_states_inputs,\n",
    "#         [decoder_outputs] + decoder_states)\n",
    " \n",
    "#     # Test correction\n",
    "#     input_seq = tokenizer.texts_to_sequences([\"I hav a qustion\"])\n",
    "#     input_seq = pad_sequences(input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "#     corrected_text = decode_sequence(input_seq)\n",
    "#     print(\"Corrected text:\", corrected_text)\n",
    "#         # ... (your existing decode_sequence function) ...\n",
    "\n",
    "#     def guess_using_spelling_model(self, clean_word):\n",
    "#         # Prepare the input sequence\n",
    "#         input_seq = self.tokenizer.texts_to_sequences([clean_word.replace('_', 'x')])  # Replace underscore with 'x' or any other character\n",
    "#         input_seq = pad_sequences(input_seq, maxlen=self.max_encoder_seq_length, padding='post')\n",
    "\n",
    "#         # Get the corrected word\n",
    "#         corrected_word = self.decode_sequence(input_seq)\n",
    "\n",
    "#         # Find the first letter in the corrected word that isn't in the current word and hasn't been guessed\n",
    "#         for letter in corrected_word:\n",
    "#             if letter not in clean_word and letter not in self.guessed_letters:\n",
    "#                 return letter\n",
    "\n",
    "#         # If no suitable letter found, fall back to frequency-based guess\n",
    "#         return self.guess_by_overall_frequency()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def short_word_strategy(self, clean_word):\n",
    "        print(\"short_word_strategy Executed\")\n",
    "        word_length = len(clean_word)\n",
    "        unknown_count = clean_word.count('_')\n",
    "        if word_length <= 7:\n",
    "            known_count = sum(1 for letter in clean_word if letter != '_')\n",
    "            \n",
    "            if known_count == 0:\n",
    "                return self.find_most_common_letter(self.current_dictionary)\n",
    "            elif 2<unknown_count<len(clean_word)-2:\n",
    "                return self.final_strategy(clean_word)\n",
    "            else:\n",
    "                # Use a combination of n-gram and spelling model\n",
    "                ngram_guess = self.calculate_trigram_probabilities(clean_word)\n",
    "                spelling_guess = self.guess_using_spelling_model(clean_word)\n",
    "                \n",
    "                if random.random() < 0.5:  # 50% chance to use each method\n",
    "                    return spelling_guess\n",
    "                else:\n",
    "                    return spelling_guess\n",
    "        \n",
    "        return self.guess(clean_word)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def guess_by_overall_frequency(self):\n",
    "    # Use the pre-calculated letter frequency from the full dictionary\n",
    "        for letter, _ in self.full_dictionary_common_letter_sorted:\n",
    "            if letter not in self.guessed_letters:\n",
    "                return letter\n",
    "        return ''  # Return empty string if all letters have been guessed\n",
    "    \n",
    "    def build_n_grams(self, dictionary):\n",
    "        '''\n",
    "        build nested dictionary containing occurences for n (1-5) sequences of letters\n",
    "        unigrams and bigrams have an extra level for length of the word\n",
    "        for unigram, take only unique letters within each word  \n",
    "        '''\n",
    "        unigram = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "        bi_gram = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int)))\n",
    "        tri_gram = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int)))\n",
    "        four_gram = collections.defaultdict(lambda:collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int))))\n",
    "        five_gram = collections.defaultdict(lambda: collections.defaultdict(lambda:collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(int)))))\n",
    "        \n",
    "        # go through each word in the dictionary\n",
    "        for word in dictionary:\n",
    "            # check each letter in the dictionary and update the n-gram\n",
    "            for i in range(len(word) - 4):\n",
    "                bi_gram[len(word)][word[i]][word[i+1]] += 1\n",
    "                tri_gram[word[i]][word[i+1]][word[i+2]] += 1\n",
    "                four_gram[word[i]][word[i+1]][word[i+2]][word[i+3]] += 1\n",
    "                five_gram[word[i]][word[i+1]][word[i+2]][word[i+3]][word[i+4]] += 1\n",
    "            i = len(word) - 4\n",
    "            \n",
    "            # fill out the rest of the n-grams for words too short\n",
    "            if len(word) == 2:\n",
    "                bi_gram[len(word)][word[0]][word[1]] += 1\n",
    "            elif len(word) == 3:\n",
    "                bi_gram[len(word)][word[0]][word[1]] += 1\n",
    "                bi_gram[len(word)][word[1]][word[2]] += 1\n",
    "                tri_gram[word[0]][word[1]][word[2]] += 1\n",
    "                \n",
    "            # fill out rest of the (1-4)-grams\n",
    "            elif len(word) >= 4:\n",
    "                bi_gram[len(word)][word[i]][word[i+1]] += 1\n",
    "                bi_gram[len(word)][word[i+1]][word[i+2]] += 1\n",
    "                bi_gram[len(word)][word[i+2]][word[i+3]] += 1\n",
    "                tri_gram[word[i]][word[i+1]][word[i+2]] += 1\n",
    "                tri_gram[word[i+1]][word[i+2]][word[i+3]] += 1\n",
    "                four_gram[word[i]][word[i+1]][word[i+2]][word[i+3]] += 1\n",
    "            \n",
    "            # fill out unigrams\n",
    "            for letter in set(word):\n",
    "                unigram[len(word)][letter] += 1\n",
    "                    \n",
    "        return unigram, bi_gram, tri_gram, four_gram, five_gram\n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def recalibrate_n_grams(self):\n",
    "        '''\n",
    "        re-tabulates the n-grams after eliminating any incorrectly guessed letters\n",
    "        updates the dictionary to remove words containing incorrectly guessed letters\n",
    "        '''\n",
    "        # updates the dictionary to remove words containing incorrectly guessed letters\n",
    "        new_dictionary = [word for word in self.full_dictionary if not set(word).intersection(set(self.incorrect_guesses))]\n",
    "        self.unigram, self.bigram, self.trigram, self.fourgram, self.fivegram = self.build_n_grams(new_dictionary)\n",
    "\n",
    "    \n",
    "    def fivegram_probs(self, word):\n",
    "        ''' \n",
    "        Input: the word in the \"clean\" format with no spaces and a '_' if letter has not been guessed\n",
    "        Flow: uses tri-gram to calculate the probability of a certain letter appearing in a five-letter sequence for a word of given length\n",
    "        Output: probabilities for each letter to be used in next level\n",
    "        '''\n",
    "                \n",
    "        # vector of probabilities for each letter\n",
    "        probs = [0] * len(self.letter_set)\n",
    "        \n",
    "        total_count = 0\n",
    "        letter_count = [0] * len(self.letter_set)\n",
    "\n",
    "        # traverse the word and find patterns that have three consecutive letters where one of them is blank\n",
    "        for i in range(len(word) - 4):\n",
    "                        \n",
    "            # case 1: \"letter letter letter letter blank\"\n",
    "            if word[i] != '_' and word[i+1] != '_' and word[i+2] != '_' and word[i+3] != '_' and word[i+4] == '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+1]\n",
    "                anchor_letter_3 = word[i+2]\n",
    "                anchor_letter_4 = word[i+3]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter_1 anchor_letter_2 blank\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fivegram[anchor_letter_1][anchor_letter_2][anchor_letter_3][anchor_letter_4][letter] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fivegram[anchor_letter_1][anchor_letter_2][anchor_letter_3][anchor_letter_4][letter]\n",
    "                        letter_count[j] += self.fivegram[anchor_letter_1][anchor_letter_2][anchor_letter_3][anchor_letter_4][letter]\n",
    "        \n",
    "            # case 2: \"letter letter letter blank letter\"\n",
    "            elif word[i] != '_' and word[i+1] != '_' and word[i+2] != '_' and word[i+3] == '_' and word[i+4] != '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+1]\n",
    "                anchor_letter_3 = word[i+2]\n",
    "                anchor_letter_4 = word[i+4]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter_1 blank anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fivegram[anchor_letter_1][anchor_letter_2][anchor_letter_3][letter][anchor_letter_4] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fivegram[anchor_letter_1][anchor_letter_2][anchor_letter_3][letter][anchor_letter_4]\n",
    "                        letter_count[j] += self.fivegram[anchor_letter_1][anchor_letter_2][anchor_letter_3][letter][anchor_letter_4]\n",
    "               \n",
    "            # case 3: letter letter blank letter letter\n",
    "            elif word[i] != '_' and word[i+1] != '_' and word[i+2] == '_' and word[i+3] != '_' and word[i+4] != '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+1]\n",
    "                anchor_letter_3 = word[i+3]\n",
    "                anchor_letter_4 = word[i+4]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter_1 anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fivegram[anchor_letter_1][anchor_letter_2][letter][anchor_letter_3][anchor_letter_4] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fivegram[anchor_letter_1][anchor_letter_2][letter][anchor_letter_3][anchor_letter_4]\n",
    "                        letter_count[j] += self.fivegram[anchor_letter_1][anchor_letter_2][letter][anchor_letter_3][anchor_letter_4]\n",
    "               \n",
    "            # case 4: letter blank letter letter letter\n",
    "            elif word[i] != '_' and word[i+1] == '_' and word[i+2] != '_' and word[i+3] != '_' and word[i+4] != '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+2]\n",
    "                anchor_letter_3 = word[i+3]\n",
    "                anchor_letter_4 = word[i+4]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter_1 anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fivegram[anchor_letter_1][letter][anchor_letter_2][anchor_letter_3][anchor_letter_4] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fivegram[anchor_letter_1][letter][anchor_letter_2][anchor_letter_3][anchor_letter_4]\n",
    "                        letter_count[j] += self.fivegram[anchor_letter_1][letter][anchor_letter_2][anchor_letter_3][anchor_letter_4]\n",
    "        \n",
    "            # case 5: blank letter letter letter letter\n",
    "            elif word[i] == '_' and word[i+1] != '_' and word[i+2] != '_' and word[i+3] != '_' and word[i+4] != '_':\n",
    "                anchor_letter_1 = word[i+1]\n",
    "                anchor_letter_2 = word[i+2]\n",
    "                anchor_letter_3 = word[i+3]\n",
    "                anchor_letter_4 = word[i+4]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter_1 anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fivegram[letter][anchor_letter_1][anchor_letter_2][anchor_letter_3][anchor_letter_4] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fivegram[letter][anchor_letter_1][anchor_letter_2][anchor_letter_3][anchor_letter_4]\n",
    "                        letter_count[j] += self.fivegram[letter][anchor_letter_1][anchor_letter_2][anchor_letter_3][anchor_letter_4]\n",
    "        \n",
    "        # calculate the probabilities of each letter appearing\n",
    "        if total_count > 0:\n",
    "            for i in range(len(self.letter_set)):\n",
    "                probs[i] = letter_count[i] / total_count\n",
    "        \n",
    "        # interpolate probabilities between trigram and bigram\n",
    "        for i, p in enumerate(self.probabilities):\n",
    "            self.probabilities[i] = p + probs[i] * (0.40)\n",
    "        \n",
    "        # run the next level down\n",
    "        return self.fourgram_probs(word)\n",
    "    \n",
    "    def fourgram_probs(self, word):\n",
    "        ''' \n",
    "        Input: the word in the \"clean\" format with no spaces and a '_' if letter has not been guessed\n",
    "        Flow: uses tri-gram to calculate the probability of a certain letter appearing in a four-letter sequence for a word of given length\n",
    "        Output: probabilities for each letter to be used in next level\n",
    "        '''\n",
    "                \n",
    "        # vector of probabilities for each letter\n",
    "        probs = [0] * len(self.letter_set)\n",
    "        \n",
    "        total_count = 0\n",
    "        letter_count = [0] * len(self.letter_set)\n",
    "\n",
    "        # traverse the word and find patterns that have three consecutive letters where one of them is blank\n",
    "        for i in range(len(word) - 3):\n",
    "                        \n",
    "            # case 1: \"letter letter letter blank\"\n",
    "            if word[i] != '_' and word[i+1] != '_' and word[i+2] != '_' and word[i+3] == '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+1]\n",
    "                anchor_letter_3 = word[i+2]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter_1 anchor_letter_2 blank\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fourgram[anchor_letter_1][anchor_letter_2][anchor_letter_3][letter] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fourgram[anchor_letter_1][anchor_letter_2][anchor_letter_3][letter]\n",
    "                        letter_count[j] += self.fourgram[anchor_letter_1][anchor_letter_2][anchor_letter_3][letter]\n",
    "        \n",
    "            # case 2: \"letter letter blank letter\"\n",
    "            elif word[i] != '_' and word[i+1] != '_' and word[i+2] == '_' and word[i+3] != '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+1]\n",
    "                anchor_letter_3 = word[i+3]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter_1 blank anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fourgram[anchor_letter_1][anchor_letter_2][letter][anchor_letter_3] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fourgram[anchor_letter_1][anchor_letter_2][letter][anchor_letter_3]\n",
    "                        letter_count[j] += self.fourgram[anchor_letter_1][anchor_letter_2][letter][anchor_letter_3]\n",
    "               \n",
    "            # case 3: letter blank letter letter\n",
    "            elif word[i] != '_' and word[i+1] == '_' and word[i+2] != '_' and word[i+3] != '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+2]\n",
    "                anchor_letter_3 = word[i+3]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter_1 anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fourgram[anchor_letter_1][letter][anchor_letter_2][anchor_letter_3] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fourgram[anchor_letter_1][letter][anchor_letter_2][anchor_letter_3]\n",
    "                        letter_count[j] += self.fourgram[anchor_letter_1][letter][anchor_letter_2][anchor_letter_3]\n",
    "               \n",
    "            # case 4: blank letter letter letter\n",
    "            elif word[i] == '_' and word[i+1] != '_' and word[i+2] != '_' and word[i+3] != '_':\n",
    "                anchor_letter_1 = word[i+1]\n",
    "                anchor_letter_2 = word[i+2]\n",
    "                anchor_letter_3 = word[i+3]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter_1 anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.fourgram[letter][anchor_letter_1][anchor_letter_2][anchor_letter_3] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.fourgram[letter][anchor_letter_1][anchor_letter_2][anchor_letter_3]\n",
    "                        letter_count[j] += self.fourgram[letter][anchor_letter_1][anchor_letter_2][anchor_letter_3]\n",
    "        \n",
    "        # calculate the probabilities of each letter appearing\n",
    "        if total_count > 0:\n",
    "            for i in range(len(self.letter_set)):\n",
    "                probs[i] = letter_count[i] / total_count\n",
    "        \n",
    "        # interpolate probabilities between trigram and bigram\n",
    "        for i, p in enumerate(self.probabilities):\n",
    "            self.probabilities[i] = p + probs[i] * (0.25)\n",
    "        \n",
    "        # run the next level down\n",
    "        return self.calculate_trigram_probabilities(word)\n",
    "\n",
    "    def calculate_trigram_probabilities(self, word):\n",
    "        ''' \n",
    "        Input: the word in the \"clean\" format with no spaces and a '_' if letter has not been guessed\n",
    "        Flow: uses tri-gram to calculate the probability of a certain letter appearing in a three-letter sequence for a word of given length\n",
    "        Output: probabilities for each letter to be used in next level\n",
    "        '''\n",
    "                \n",
    "        # vector of probabilities for each letter\n",
    "        probs = [0] * len(self.letter_set)\n",
    "        \n",
    "        total_count = 0\n",
    "        letter_count = [0] * len(self.letter_set)\n",
    "\n",
    "        # traverse the word and find patterns that have three consecutive letters where one of them is blank\n",
    "        for i in range(len(word) - 2):\n",
    "                        \n",
    "            # case 1: \"letter letter blank\"\n",
    "            if word[i] != '_' and word[i+1] != '_' and word[i+2] == '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+1]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter_1 anchor_letter_2 blank\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.trigram[anchor_letter_1][anchor_letter_2][letter] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.trigram[anchor_letter_1][anchor_letter_2][letter]\n",
    "                        letter_count[j] += self.trigram[anchor_letter_1][anchor_letter_2][letter]\n",
    "        \n",
    "            # case 2: \"letter blank letter\"\n",
    "            elif word[i] != '_' and word[i+1] == '_' and word[i+2] != '_':\n",
    "                anchor_letter_1 = word[i]\n",
    "                anchor_letter_2 = word[i+2]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter_1 blank anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.trigram[anchor_letter_1][letter][anchor_letter_2] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.trigram[anchor_letter_1][letter][anchor_letter_2]\n",
    "                        letter_count[j] += self.trigram[anchor_letter_1][letter][anchor_letter_2]\n",
    "               \n",
    "            # case 3: blank letter letter\n",
    "            elif word[i] == '_' and word[i+1] != '_' and word[i+2] != '_':\n",
    "                anchor_letter_1 = word[i+1]\n",
    "                anchor_letter_2 = word[i+2]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter_1 anchor_letter_2\" and for each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.trigram[letter][anchor_letter_1][anchor_letter_2] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.trigram[letter][anchor_letter_1][anchor_letter_2]\n",
    "                        letter_count[j] += self.trigram[letter][anchor_letter_1][anchor_letter_2]\n",
    "        \n",
    "        # calculate the probabilities of each letter appearing\n",
    "        if total_count > 0:\n",
    "            for i in range(len(self.letter_set)):\n",
    "                probs[i] = letter_count[i] / total_count\n",
    "        \n",
    "        # interpolate probabilities between trigram and bigram\n",
    "        for i, p in enumerate(self.probabilities):\n",
    "            self.probabilities[i] = p + probs[i] * (0.20)\n",
    "        \n",
    "        # run the next level down\n",
    "        return self.bigram_probs(word)\n",
    "    \n",
    "    \n",
    "    def bigram_probs(self, word):\n",
    "        ''' \n",
    "        Input: the word in the \"clean\" format with no spaces and a '_' if letter has not been guessed\n",
    "        Flow: uses bi-gram to calculate the probability of a certain letter appearing in a two-letter sequence for a word of given length\n",
    "              updates the probabilities set in trigram_probs\n",
    "        Output: probabilities for each letter to be used in next level\n",
    "        '''\n",
    "        \n",
    "        # vector of probabilities for each letter\n",
    "        probs = [0] * len(self.letter_set)\n",
    "        \n",
    "        total_count = 0\n",
    "        letter_count = [0] * len(self.letter_set)\n",
    "        \n",
    "        # traverse the word and find either patterns of \"letter blank\" or \"blank letter\"\n",
    "        for i in range(len(word) - 1):\n",
    "            # case 1: \"letter blank\"\n",
    "            if word[i] != '_' and word[i+1] == '_':\n",
    "                anchor_letter = word[i]\n",
    "                \n",
    "                # calculate occurences of \"anchor_letter blank\" and each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.bigram[len(word)][anchor_letter][letter] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.bigram[len(word)][anchor_letter][letter]\n",
    "                        letter_count[j] += self.bigram[len(word)][anchor_letter][letter]\n",
    "                            \n",
    "            # case 2: \"blank letter\"\n",
    "            elif word[i] == '_' and word[i+1]!= '_':\n",
    "                anchor_letter = word[i+1]\n",
    "                \n",
    "                # calculate occurences of \"blank anchor_letter\" and each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.bigram[len(word)][letter][anchor_letter] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.bigram[len(word)][letter][anchor_letter]\n",
    "                        letter_count[j] += self.bigram[len(word)][letter][anchor_letter]\n",
    "                                                                    \n",
    "        # calculate the probabilities of each letter appearing\n",
    "        if total_count > 0:\n",
    "            for i in range(len(self.letter_set)):\n",
    "                probs[i] = letter_count[i] / total_count\n",
    "\n",
    "        # interpolate probabilities between trigram and bigram\n",
    "        for i, p in enumerate(self.probabilities):\n",
    "            self.probabilities[i] = p + probs[i] * (0.10)\n",
    "        \n",
    "        # return letter associated with highest probability\n",
    "        return self.unigram_probs(word)\n",
    "    \n",
    "    \n",
    "    def unigram_probs(self, word):\n",
    "        ''' \n",
    "        Input: the word in the \"clean\" format with no spaces and a '_' if letter has not been guessed\n",
    "        Flow: uses unigram to calculate the probability of a certain letter appearing in a any blank space\n",
    "              updates the probabilities set in bigram_probs\n",
    "        Output: letter with the overall highest probability\n",
    "        '''\n",
    "                \n",
    "        # vector of probabilities for each letter\n",
    "        probs = [0] * len(self.letter_set)\n",
    "        \n",
    "        total_count = 0\n",
    "        letter_count = [0] * len(self.letter_set)\n",
    "        \n",
    "        # traverse the word and find blank spaces\n",
    "        for i in range(len(word)):\n",
    "            # case 1: \"letter blank\"\n",
    "            if word[i] == '_':\n",
    "                                \n",
    "                # calculate occurences of pattern and each letter not guessed yet\n",
    "                for j, letter in enumerate(self.letter_set):\n",
    "                    if self.unigram[len(word)][letter] > 0 and letter not in self.guessed_letters:\n",
    "                        total_count += self.unigram[len(word)][letter]\n",
    "                        letter_count[j] += self.unigram[len(word)][letter]\n",
    "                       \n",
    "        # calculate the probabilities of each letter appearing\n",
    "        if total_count > 0:\n",
    "            for i in range(len(self.letter_set)):\n",
    "                probs[i] = letter_count[i] / total_count\n",
    "                \n",
    "        # interpolate probabilities\n",
    "        for i, p in enumerate(self.probabilities):\n",
    "            self.probabilities[i] = p + probs[i] * (0.05)\n",
    "        \n",
    "        # adjust probabilities so they sum to one (not necessary but looks better)\n",
    "        final_probs = [0] * len(self.letter_set)\n",
    "        if sum(self.probabilities) > 0:\n",
    "            for i in range(len(self.probabilities)):\n",
    "                final_probs[i] = self.probabilities[i] / sum(self.probabilities)\n",
    "            \n",
    "        self.probabilities = final_probs\n",
    "        \n",
    "        # find letter with largest probability\n",
    "        max_prob = 0\n",
    "        guess_letter = ''\n",
    "        for i, letter in enumerate(self.letter_set):\n",
    "            if self.probabilities[i] > max_prob:\n",
    "                max_prob = self.probabilities[i]\n",
    "                guess_letter = letter\n",
    "        \n",
    "        # if no letter chosen from above, pick a random one (extra weight on vowels)\n",
    "        if guess_letter == '':\n",
    "            letters = self.letter_set.copy()\n",
    "            random.shuffle(letters)\n",
    "            letters_shuffled = ['e','a','i','o','u'] + letters\n",
    "            for letter in letters_shuffled:\n",
    "                if letter not in self.guessed_letters:\n",
    "                    return letter\n",
    "            \n",
    "        return guess_letter\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def calculate_trigram_probabilities(self,word):\n",
    "        \n",
    "        trigram_counts = collections.defaultdict(int)\n",
    "        bigram_counts = collections.defaultdict(int)\n",
    "    \n",
    "        for word in self.full_dictionary:\n",
    "            padded_word = '_' + word + '_'  # Add padding to consider start and end of words\n",
    "            for i in range(len(padded_word) - 2):\n",
    "                trigram = padded_word[i:i+3]\n",
    "                trigram_counts[trigram] += 1\n",
    "                bigram_counts[trigram[:2]] += 1\n",
    "    \n",
    "        trigram_probs = {}\n",
    "        for trigram, count in trigram_counts.items():\n",
    "            bigram = trigram[:2]\n",
    "            trigram_probs[trigram] = count / bigram_counts[bigram]\n",
    "    \n",
    "        return trigram_probs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def guess_using_trigrams(self, clean_word):\n",
    "        unknown_positions = [i for i, letter in enumerate(clean_word) if letter == '_']\n",
    "        padded_word = '_' + clean_word + '_'\n",
    "    \n",
    "        letter_scores = collections.defaultdict(float)\n",
    "    \n",
    "        for pos in unknown_positions:\n",
    "            prev_bigram = padded_word[pos:pos+2]\n",
    "            next_bigram = padded_word[pos+1:pos+3]\n",
    "        \n",
    "            for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                if letter not in self.guessed_letters:\n",
    "                    prev_trigram = prev_bigram[0] + letter + prev_bigram[1]\n",
    "                    next_trigram = letter + next_bigram\n",
    "                \n",
    "                    prev_score = self.trigram_probs.get(prev_trigram, 0)\n",
    "                    next_score = self.trigram_probs.get(next_trigram, 0)\n",
    "                \n",
    "                    letter_scores[letter] += prev_score + next_score\n",
    "    \n",
    "        if letter_scores:\n",
    "            return max(letter_scores, key=letter_scores.get)\n",
    "        \n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    def find_most_common_letter(self, words):\n",
    "        letter_count = {}\n",
    "        for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            letter_count[letter] = sum(1 for word in words if letter in word)\n",
    "        return max((letter for letter in letter_count if letter not in self.guessed_letters), \n",
    "                   key=letter_count.get, default='')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def intermediate_strategy(self, clean_word):\n",
    "        # This function implements the strategy for when we have 100 or fewer words\n",
    "        letter_freq = {}\n",
    "        for word in self.current_dictionary:\n",
    "            for letter in set(word):\n",
    "                if letter not in self.guessed_letters:\n",
    "                    letter_freq[letter] = letter_freq.get(letter, 0) + 1\n",
    "        \n",
    "        # Return the letter that appears in the most words\n",
    "        return max(letter_freq, key=letter_freq.get) if letter_freq else ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def calculate_transition_probabilities(self, position='pre'):\n",
    "        transition_probs = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "        total_counts = collections.defaultdict(int)\n",
    "        \n",
    "        for word in self.full_dictionary:\n",
    "            for i in range(len(word) - 1):\n",
    "                if position == 'pre':\n",
    "                    transition_probs[word[i]][word[i+1]] += 1\n",
    "                    total_counts[word[i]] += 1\n",
    "                else:  # post\n",
    "                    transition_probs[word[i+1]][word[i]] += 1\n",
    "                    total_counts[word[i+1]] += 1\n",
    "        \n",
    "        for char in transition_probs:\n",
    "            for next_char in transition_probs[char]:\n",
    "                transition_probs[char][next_char] /= total_counts[char]\n",
    "        \n",
    "        return transition_probs\n",
    "\n",
    "    def calculate_pair_probabilities(self):\n",
    "        pair_probs = collections.defaultdict(int)\n",
    "        total_pairs = 0\n",
    "        \n",
    "        for word in self.full_dictionary:\n",
    "            for i in range(len(word) - 1):\n",
    "                pair_probs[word[i:i+2]] += 1\n",
    "                total_pairs += 1\n",
    "        \n",
    "        for pair in pair_probs:\n",
    "            pair_probs[pair] /= total_pairs\n",
    "        \n",
    "        return pair_probs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def final_strategy(self, clean_word):\n",
    "        unknown_positions = [i for i, letter in enumerate(clean_word) if letter == '_']\n",
    "    \n",
    "        if len(unknown_positions) == 1:\n",
    "        # Use the n-gram approach for the last letter\n",
    "            return self.guess_last_letter_ngram(clean_word)\n",
    "        elif 6 > len(unknown_positions) > 1:\n",
    "        # Keep your existing strategy for multiple unknown letters\n",
    "            return self.guess_last_letter_ngram(clean_word)\n",
    "        else:\n",
    "        # Fallback to overall letter frequency if no unknowns (shouldn't happen, but just in case)\n",
    "            return self.guess_by_overall_frequency()\n",
    "\n",
    "    def guess_last_letter_ngram(self, clean_word):\n",
    "        print(\"Final Strategyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\")\n",
    "        unknown_position = clean_word.index('_')\n",
    "        word_length = len(clean_word)\n",
    "    \n",
    "    # Reset probabilities\n",
    "        self.probabilities = [0] * len(self.letter_set)\n",
    "    \n",
    "    # Apply 5-gram\n",
    "        self.fivegram_probs(clean_word)\n",
    "      \n",
    "    # Apply 4-gram\n",
    "        self.fourgram_probs(clean_word)\n",
    "    \n",
    "    # Apply 3-gram\n",
    "        self.calculate_trigram_probabilities(clean_word)\n",
    "    \n",
    "    # Apply 2-gram\n",
    "        self.bigram_probs(clean_word)\n",
    "    \n",
    "    # Apply 1-gram\n",
    "        self.unigram_probs(clean_word)\n",
    "    \n",
    "    # Find letter with largest probability\n",
    "        max_prob = 0\n",
    "        guess_letter = ''\n",
    "        for i, letter in enumerate(self.letter_set):\n",
    "            if self.probabilities[i] > max_prob and letter not in self.guessed_letters:\n",
    "                max_prob = self.probabilities[i]\n",
    "                guess_letter = letter\n",
    "    \n",
    "    # If no letter chosen from above, pick a random unguessed letter\n",
    "        if guess_letter == '':\n",
    "            unguessed = [letter for letter in self.letter_set if letter not in self.guessed_letters]\n",
    "            if unguessed:\n",
    "                return final_strategy()\n",
    "    \n",
    "        return guess_letter\n",
    "    \n",
    "    def final_strategy2(self, clean_word):\n",
    "        print(\"stat222222222222222222222222222222222222222\")\n",
    "        unknown_positions = [i for i, letter in enumerate(clean_word) if letter == '_']\n",
    "        \n",
    "        if len(unknown_positions) == 2:\n",
    "            if unknown_positions[1] - unknown_positions[0] > 1:  # Non-adjacent unknowns\n",
    "                pre_letter = clean_word[unknown_positions[0] - 1] if unknown_positions[0] > 0 else None\n",
    "                post_letter = clean_word[unknown_positions[1] + 1] if unknown_positions[1] < len(clean_word) - 1 else None\n",
    "                \n",
    "                pre_probs = self.calculate_transition_probabilities('pre')\n",
    "                post_probs = self.calculate_transition_probabilities('post')\n",
    "                \n",
    "                combined_probs = {}\n",
    "                for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                    if letter not in self.guessed_letters:\n",
    "                        pre_prob = pre_probs[pre_letter][letter] if pre_letter else 1\n",
    "                        post_prob = post_probs[post_letter][letter] if post_letter else 1\n",
    "                        combined_probs[letter] = pre_prob * post_prob\n",
    "                \n",
    "                guess_letters = sorted(combined_probs, key=combined_probs.get, reverse=True)[:2]\n",
    "            else:  # Adjacent unknowns (including end cases)\n",
    "                if unknown_positions[0] == 0:  # Start of word\n",
    "                    known_letter = clean_word[unknown_positions[1] + 1]\n",
    "                    probs = self.calculate_transition_probabilities('pre')\n",
    "                elif unknown_positions[1] == len(clean_word) - 1:  # End of word\n",
    "                    known_letter = clean_word[unknown_positions[0] - 1]\n",
    "                    probs = self.calculate_transition_probabilities('post')\n",
    "                else:  # Middle of word\n",
    "                    pre_letter = clean_word[unknown_positions[0] - 1]\n",
    "                    post_letter = clean_word[unknown_positions[1] + 1]\n",
    "                    pre_probs = self.calculate_transition_probabilities('pre')\n",
    "                    post_probs = self.calculate_transition_probabilities('post')\n",
    "                    pair_probs = self.calculate_pair_probabilities()\n",
    "                \n",
    "                combined_probs = {}\n",
    "                if unknown_positions[0] == 0 or unknown_positions[1] == len(clean_word) - 1:\n",
    "                    for letter1 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        if letter1 not in self.guessed_letters:\n",
    "                            for letter2 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                                if letter2 not in self.guessed_letters and letter2 != letter1:\n",
    "                                    if unknown_positions[0] == 0:\n",
    "                                        prob = probs[known_letter][letter2]\n",
    "                                    else:\n",
    "                                        prob = probs[known_letter][letter1]\n",
    "                                    combined_probs[(letter1, letter2)] = prob\n",
    "                else:\n",
    "                    for letter1 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                        if letter1 not in self.guessed_letters:\n",
    "                            for letter2 in 'abcdefghijklmnopqrstuvwxyz':\n",
    "                                if letter2 not in self.guessed_letters and letter2 != letter1:\n",
    "                                    pre_prob = pre_probs[pre_letter][letter1]\n",
    "                                    post_prob = post_probs[post_letter][letter2]\n",
    "                                    pair_prob = pair_probs.get(letter1 + letter2, 1e-10)  # Small value to avoid division by zero\n",
    "                                    combined_probs[(letter1, letter2)] = (pre_prob * post_prob) / pair_prob\n",
    "                \n",
    "                guess_letters = sorted(combined_probs, key=combined_probs.get, reverse=True)[0]\n",
    "            \n",
    "            self.final_strategy_second_guess = guess_letters[1]\n",
    "            return guess_letters[0]\n",
    "        elif hasattr(self, 'final_strategy_second_guess'):\n",
    "            guess_letter = self.final_strategy_second_guess\n",
    "            del self.final_strategy_second_guess\n",
    "            return guess_letter\n",
    "        else:\n",
    "            # Fallback to previous strategy if we have only one unknown\n",
    "            letter_freq = {}\n",
    "            for word in self.current_dictionary:\n",
    "                for pos in unknown_positions:\n",
    "                    letter = word[pos]\n",
    "                    if letter not in self.guessed_letters:\n",
    "                        letter_freq[letter] = letter_freq.get(letter, 0) + 1\n",
    "            return max(letter_freq, key=letter_freq.get) if letter_freq else ''\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def guess(self, word):\n",
    "        clean_word = word[::2]\n",
    "        word_length = len(clean_word)\n",
    "\n",
    "        # If this is the first guess, create a new dictionary with words of the same length\n",
    "        if not self.guessed_letters:\n",
    "            self.current_dictionary = [w for w in self.full_dictionary if len(w) == word_length]\n",
    "        else:\n",
    "        # Update the dictionary based on the last guess\n",
    "            last_guess = self.guessed_letters[-1]\n",
    "            new_dictionary = []\n",
    "            for w in self.current_dictionary:\n",
    "                if last_guess in clean_word:\n",
    "                    if all((w[i] == last_guess) == (clean_word[i] == last_guess) for i in range(word_length)):\n",
    "                        new_dictionary.append(w)\n",
    "                else:\n",
    "                    if last_guess not in w:\n",
    "                        new_dictionary.append(w)\n",
    "            self.current_dictionary = new_dictionary\n",
    "        # Count unknown positions\n",
    "        unknown_count = clean_word.count('_')\n",
    "        # Use the main strategy until we're left with 100 or fewer words\n",
    "        if len(clean_word)>10:\n",
    "        \n",
    "            if unknown_count > len(clean_word)-3:\n",
    "                guess_letter = self.find_most_common_letter(self.current_dictionary)\n",
    "                    # Switch to the intermediate strategy when we have 100 or fewer words\n",
    "#         elif unknown_count > 1:\n",
    "#             guess_letter = self.final_strategy2(clean_word)\n",
    "\n",
    "        # Switch to the final strategy when we have 2 or fewer unknown positions\n",
    "            else:\n",
    "                guess_letter = self.final_strategy(clean_word)\n",
    "        \n",
    "        elif word_length <= 7:\n",
    "            if unknown_count>len(clean_word)-2:\n",
    "                guess_letter = self.find_most_common_letter(self.current_dictionary)\n",
    "            elif 2<unknown_count<len(clean_word)-2:\n",
    "                guess_letter = self.final_strategy(clean_word)\n",
    "            else:    \n",
    "                return self.short_word_strategy(clean_word)\n",
    "\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            if unknown_count > len(clean_word)-4:\n",
    "                guess_letter = self.find_most_common_letter(self.current_dictionary)\n",
    "                    # Switch to the intermediate strategy when we have 100 or fewer words\n",
    "#         elif unknown_count > 1:\n",
    "#             guess_letter = self.final_strategy2(clean_word)\n",
    "\n",
    "        # Switch to the final strategy when we have 2 or fewer unknown positions\n",
    "            else:\n",
    "                guess_letter = self.final_strategy(clean_word)\n",
    "           \n",
    "        # If we can't find a new letter to guess, guess a random unguessed letter\n",
    "        if not guess_letter:\n",
    "            alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "            unguessed = [letter for letter in alphabet if letter not in self.guessed_letters]\n",
    "            guess_letter = random.choice(unguessed) if unguessed else ''\n",
    "\n",
    "        if guess_letter:\n",
    "            self.guessed_letters.append(guess_letter)\n",
    "            \n",
    "        else:\n",
    "            print(\"No more letters to guess.\")\n",
    "            \n",
    "        \n",
    "        return guess_letter\n",
    "     \n",
    "        \n",
    "# Replace with your own \"guess\" function here #\n",
    "###############################################\n",
    "##########################################################\n",
    "    # You'll likely not need to modify any of the code below #\n",
    "    ##########################################################\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "                         \n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                # get guessed letter from user code\n",
    "                guess_letter = self.guess(word)\n",
    "                    \n",
    "                # append guessed letter to guessed letters field in hangman object\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                    \n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "               \n",
    "                if verbose:\n",
    "                    print(\"Sever response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "    \n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        # Add `access_token` to post_args or args if it has not already been\n",
    "        # included.\n",
    "        if self.access_token:\n",
    "            # If post_args exists, we assume that args either does not exists\n",
    "            # or it does not need `access_token`.\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "    \n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To start a new game:\n",
    "1. Make sure you have implemented your own \"guess\" method.\n",
    "2. Use the access_token that we sent you to create your HangmanAPI object. \n",
    "3. Start a game by calling \"start_game\" method.\n",
    "4. If you wish to test your function without being recorded, set \"practice\" parameter to 1.\n",
    "5. Note: You have a rate limit of 20 new games per minute. DO NOT start more than 20 new games within one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "api = HangmanAPI(access_token=\"7af05f308f446e991c5c4a9b4775d9\", timeout=2000)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully start a new game! Game ID: e2ea9f6653e2. # of tries remaining: 6. Word: _ _ _ _ _ _ _ .\n",
      "Guessing letter: e\n",
      "Sever response: {'game_id': 'e2ea9f6653e2', 'status': 'ongoing', 'tries_remains': 6, 'word': '_ _ _ _ _ e _ '}\n",
      "Guessing letter: r\n",
      "Sever response: {'game_id': 'e2ea9f6653e2', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ e _ '}\n",
      "Guessing letter: s\n",
      "Sever response: {'game_id': 'e2ea9f6653e2', 'status': 'ongoing', 'tries_remains': 5, 'word': '_ _ _ _ _ e s '}\n",
      "short_word_strategy Executed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_3\" is incompatible with the layer: expected shape=(None, None, 26), found shape=(1, 29, 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13060\\4162587571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpractice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal_practice_runs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_recorded_runs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_recorded_successes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_practice_successes\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmy_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get my game stats: (# of tries, # of wins)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpractice_success_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_practice_successes\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_practice_runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run %d practice games out of an allotted 100,000. practice success rate so far = %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_practice_runs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpractice_success_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13060\\362280207.py\u001b[0m in \u001b[0;36mstart_game\u001b[1;34m(self, practice, verbose)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mtries_remains\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m                 \u001b[1;31m# get guessed letter from user code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m                 \u001b[0mguess_letter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m                 \u001b[1;31m# append guessed letter to guessed letters field in hangman object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13060\\362280207.py\u001b[0m in \u001b[0;36mguess\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    979\u001b[0m                 \u001b[0mguess_letter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshort_word_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13060\\362280207.py\u001b[0m in \u001b[0;36mshort_word_strategy\u001b[1;34m(self, clean_word)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;31m# Use a combination of n-gram and spelling model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0mngram_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_trigram_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m                 \u001b[0mspelling_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguess_using_spelling_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 50% chance to use each method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13060\\362280207.py\u001b[0m in \u001b[0;36mguess_using_spelling_model\u001b[1;34m(self, clean_word)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# Get the corrected word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mcorrected_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq_one_hot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Find the first letter in the corrected word that isn't in the current word and hasn't been guessed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13060\\362280207.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(self, input_seq)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m       \u001b[1;31m# Encode the input as state vectors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mstates_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m# Generate empty target sequence of length 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m                         raise ValueError(\n\u001b[0m\u001b[0;32m    246\u001b[0m                             \u001b[1;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m                             \u001b[1;34m\"incompatible with the layer: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_3\" is incompatible with the layer: expected shape=(None, None, 26), found shape=(1, 29, 27)"
     ]
    }
   ],
   "source": [
    "api.start_game(practice=1,verbose=True)\n",
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "practice_success_rate = total_practice_successes / total_practice_runs\n",
    "print('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing practice games:\n",
    "You can use the command below to play up to 100,000 practice games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_practice_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6616\\1326746598.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Continue the loop until the practice success rate reaches the target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwhile\u001b[0m \u001b[0mtotal_practice_runs\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m610\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Start a new game\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpractice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_practice_runs' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming the provided code is part of a larger script or function\n",
    "\n",
    "# Set the target practice success rate\n",
    "target_success_rate = 0.50\n",
    "\n",
    "# Continue the loop until the practice success rate reaches the target\n",
    "while practice_success_rate < target_success_rate and total_practice_runs < 610:\n",
    "    # Start a new game\n",
    "    api.start_game(practice=1, verbose=True)\n",
    "\n",
    "    # Get updated game stats\n",
    "    [total_practice_runs, total_recorded_runs, total_recorded_successes, total_practice_successes] = api.my_status()\n",
    "\n",
    "    # Calculate the practice success rate\n",
    "    practice_success_rate = total_practice_successes / total_practice_runs\n",
    "\n",
    "    # Print the current status\n",
    "    print('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))\n",
    "\n",
    "# Print a message when the loop exits\n",
    "if practice_success_rate >= target_success_rate:\n",
    "    print(\"Achieved the target practice success rate of %.3f!\" % target_success_rate)\n",
    "else:\n",
    "    print(\"Exceeded the maximum allowed practice games (100,000) without reaching the target success rate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing recorded games:\n",
    "Please finalize your code prior to running the cell below. Once this code executes once successfully your submission will be finalized. Our system will not allow you to rerun any additional games.\n",
    "\n",
    "Please note that it is expected that after you successfully run this block of code that subsequent runs will result in the error message \"Your account has been deactivated\".\n",
    "\n",
    "Once you've run this section of the code your submission is complete. Please send us your source code via email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print('Playing ', i, ' th game')\n",
    "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "    #api.start_game(practice=0,verbose=False)\n",
    "    \n",
    "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To check your game statistics\n",
    "1. Simply use \"my_status\" method.\n",
    "2. Returns your total number of games, and number of wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16920\\298256455.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtotal_practice_runs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_recorded_runs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_recorded_successes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_practice_successes\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmy_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Get my game stats: (# of tries, # of wins)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msuccess_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_recorded_successes\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_recorded_runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'overall success rate = %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msuccess_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "success_rate = total_recorded_successes/total_recorded_runs\n",
    "print('overall success rate = %.3f' % success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
